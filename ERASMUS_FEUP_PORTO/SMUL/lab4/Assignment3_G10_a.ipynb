{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "keP_1YyORjVH"
   },
   "source": [
    "# Assignment A3. Pitch and Rhythm\n",
    "\n",
    "The goal of this assignment is the exploration of classic algorithms (e.g. autocorrelation, DFT-based) to extract fundamental information from musical signals:\n",
    "- Pitch (in monophonic signals)\n",
    "- Beats and Tempo;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D1mco64Farg1"
   },
   "source": [
    "## Task 1 - Pitch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sBgcYza4RjVJ"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy, scipy, matplotlib.pyplot as plt, IPython.display as ipd\n",
    "import librosa, librosa.display\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Ni7NRjEqWHCr",
    "outputId": "2455d393-cb4f-422d-974f-281cba107f83"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-386ea5a44fbf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# drive.mount('/content/drive')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"/content/drive\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "# drive.mount('/content/drive')\n",
    "drive.mount(\"/content/drive\", force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Drpv4yvMW1zS"
   },
   "outputs": [],
   "source": [
    "path = \"/content/drive/My Drive/[Σχολή]/Erasmus/FEUP - Multimedia/Assignment_3/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "colab_type": "code",
    "id": "hc2cJm-rRjVP",
    "outputId": "c506d7df-3348-4905-aec3-fa57c8ca082c"
   },
   "outputs": [],
   "source": [
    "audio_files = \"Sounds/\"\n",
    "x, sr = librosa.load(path+audio_files+'oboe.wav')\n",
    "ipd.Audio(x, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "FyxuZkxKRjVV",
    "outputId": "02253847-ff98-490c-97ab-bfc99d3695f2"
   },
   "outputs": [],
   "source": [
    "print(sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 351
    },
    "colab_type": "code",
    "id": "5lUYXgOcRjVa",
    "outputId": "b2827937-6e92-440c-8440-efea1f67b609"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 5))\n",
    "librosa.display.waveplot(x, sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "colab_type": "code",
    "id": "Gq9OlDFhRjVf",
    "outputId": "bde7a9d3-0016-4042-fb6d-aecc6ba75a55"
   },
   "outputs": [],
   "source": [
    "x2, sr2 = librosa.load(path+audio_files+'organ.wav')\n",
    "ipd.Audio(x2, rate=sr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 351
    },
    "colab_type": "code",
    "id": "4sCAu1gYRjVk",
    "outputId": "171f9713-792a-411b-aed3-c8f97338d60c"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 5))\n",
    "librosa.display.waveplot(x2, sr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 339
    },
    "colab_type": "code",
    "id": "0zWxWwZ7RjVp",
    "outputId": "6eb60d90-fc64-493f-f1e2-791a7a9dce14"
   },
   "outputs": [],
   "source": [
    "r = librosa.autocorrelate(x, max_size=5000)\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.plot(r[:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c5916tHKRjVy"
   },
   "source": [
    "### Oboe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ILrmj8ScRjVz"
   },
   "source": [
    "The autocorrelation always has a maximum at zero, i.e. zero lag. We want to identify the maximum outside of the peak centered at zero. Therefore, we might choose only to search within a range of reasonable pitches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "938q_Bc4RjV0"
   },
   "outputs": [],
   "source": [
    "midi_hi = 120.0\n",
    "midi_lo = 12.0\n",
    "f_hi = librosa.midi_to_hz(midi_hi)\n",
    "f_lo = librosa.midi_to_hz(midi_lo)\n",
    "t_lo = sr/f_hi\n",
    "t_hi = sr/f_lo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "a-P2xlDvRjV4",
    "outputId": "468b5b3e-e322-4127-933c-1f4c71b24df2"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'f_lo' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-51a8bdd58f74>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Low freq: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf_lo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"High freq: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf_hi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Time Low: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt_lo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\" Time high: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt_hi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'f_lo' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Low freq: \", f_lo, \"High freq: \", f_hi)\n",
    "print(\"Time Low: \", t_lo, \" Time high: \", t_hi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hF45Z-SnRjV9"
   },
   "source": [
    "Set invalid pitch candidates to zero:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "colab_type": "code",
    "id": "holsxGW4RjV9",
    "outputId": "b31f6f81-f448-488c-b21c-1a82fa23342b"
   },
   "outputs": [],
   "source": [
    "r[:int(t_lo)] = 0\n",
    "r[int(t_hi):] = 0\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.plot(r[:1400])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ESLNMTUzRjWD"
   },
   "source": [
    "Find the location of the maximum:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "KTImohY1RjWE",
    "outputId": "3f460e9a-d4ee-462e-e984-16e436f7276a"
   },
   "outputs": [],
   "source": [
    "t_max = r.argmax()\n",
    "print(t_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3Edq5GUfRjWH"
   },
   "source": [
    "Finally, estimate the pitch in Hertz:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "R0tYXWIURjWI",
    "outputId": "786a00f5-3c6a-417e-ded4-b5766d30d460"
   },
   "outputs": [],
   "source": [
    "float(sr)/t_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IvwUNQPCRjWM"
   },
   "source": [
    "Value coresponds to A4 (69), source: https://musicinformationretrieval.com/midi_conversion_table.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "vIUVdvDSRjWM",
    "outputId": "d0066a6c-d977-464e-e1f3-23c81ec2036f"
   },
   "outputs": [],
   "source": [
    "librosa.midi_to_hz(69)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H7uTgAYORjWR"
   },
   "source": [
    "### Organ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "colab_type": "code",
    "id": "l9gTwWIqRjWS",
    "outputId": "fe0b801b-aea8-4f09-d96f-f64c870b3961"
   },
   "outputs": [],
   "source": [
    "r2 = librosa.autocorrelate(x2, max_size=5000)\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.plot(r2[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "sW7oTIZVRjWa",
    "outputId": "d3227f65-7162-47ff-c547-9fbda66173f1"
   },
   "outputs": [],
   "source": [
    "print(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MED7FxAeRjWd"
   },
   "outputs": [],
   "source": [
    "midi_hi = 120.0\n",
    "midi_lo = 12.0\n",
    "f_hi = librosa.midi_to_hz(midi_hi)\n",
    "f_lo = librosa.midi_to_hz(midi_lo)\n",
    "t_lo = sr2/f_hi\n",
    "t_hi = sr2/f_lo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "colab_type": "code",
    "id": "TAjFpHjvRjWh",
    "outputId": "3455f4be-17b4-42f2-bc6b-beca5e1deed0"
   },
   "outputs": [],
   "source": [
    "r2[:int(t_lo)] = 0\n",
    "r2[int(t_hi):] = 0\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.plot(r2[:1400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "N2N7KT_ERjWl",
    "outputId": "ead311f7-59a0-4712-cc61-2b95e445cd2b"
   },
   "outputs": [],
   "source": [
    "t_max2 = r2.argmax()\n",
    "print(t_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "3GGSxgjSRjWr",
    "outputId": "18b60b67-576b-43df-bba1-00ea7f1ffde2"
   },
   "outputs": [],
   "source": [
    "pitch = float(sr)/t_max2\n",
    "midi_rep = librosa.hz_to_midi(pitch)\n",
    "\n",
    "note = librosa.midi_to_note(midi_rep)\n",
    "print(note)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9dz8zlfCRjXK"
   },
   "source": [
    "Value coresponds to C4 (60), source: https://musicinformationretrieval.com/midi_conversion_table.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "XBHGIYyqRjXN",
    "outputId": "82e5dd2f-f2c4-4f6c-b424-975e03e939d8"
   },
   "outputs": [],
   "source": [
    "librosa.midi_to_hz(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KdOQPIwDRjXc"
   },
   "source": [
    "#### Is this value correct or incorrect?\n",
    "To verify the results, we opened to sonic visuliser and we analyzed the files. Here are results:\n",
    "#### Oboe\n",
    "[Chromagram of oboe](https://drive.google.com/file/d/1hQ3EswnG5kMecmwKZ6-Q1ihhZvsqX57n/view?usp=sharing)\n",
    "//\n",
    "Chromagram for oboe shows notes A + A# which corresponds with computed notes.\n",
    "\n",
    "#### Organ\n",
    "[Chromagram of organ](https://drive.google.com/file/d/1hQ3EswnG5kMecmwKZ6-Q1ihhZvsqX57n/view?usp=sharing)\n",
    "//\n",
    "Chromagram for oboe shows notes B+C+C# which also corresponds with computed notes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RCGAnxQYRjXd"
   },
   "source": [
    "### Global Analysis\n",
    "On the previous task, your pitch estimates were frame-based. For the same signals, extend this frame analysis to the full sound, and for each sound:\n",
    " 1. obtain a plot of the pitch estimation; on the x-axis you’ll have the frame number, on the y-axis the pitch/f0 in Hz.\n",
    " 2. obtain a plot of the pitch estimation; on the x-axis you’ll have the frame number, on the y-axis the pitch/f0 in MIDI Note (ex. A0, B0, B1)\n",
    " 3. Is any of these representations ( 1) or 2) ) a chromagram? Explain your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t423hW-vRjXf"
   },
   "outputs": [],
   "source": [
    "def pitch_detection_in_frames(x, frame_length=2048, hop_length=512):\n",
    "    frames = librosa.util.frame(x, frame_length=frame_length, hop_length=hop_length); #2048\n",
    "    total_frames, num_of_values_in_frame = frames.shape;\n",
    "    pitch_arr_hz = []\n",
    "    pitch_arr_midi = []\n",
    "    for i in range(total_frames):\n",
    "        pitch_max = frames[i].argmax() # counting the pitch for each frame\n",
    "        if (pitch_max == 0):\n",
    "            pitch_arr_hz.append(0)\n",
    "            pitch_arr_midi.append(0)\n",
    "        else:\n",
    "            pitch_hz = float(sr)/pitch_max\n",
    "            pitch_arr_hz.append(pitch_hz) # creating the array with pitches\n",
    "            midi_rep = librosa.hz_to_midi(pitch_hz)\n",
    "            pitch_arr_midi.append(midi_rep)\n",
    "\n",
    "    plt.figure(figsize=(14, 5))\n",
    "    plt.plot(pitch_arr_hz, 'ro')\n",
    "    plt.xlabel(\"frame\")\n",
    "    plt.ylabel(\"Hz\")\n",
    "    \n",
    "    plt.figure(figsize=(14, 5))\n",
    "    plt.plot(pitch_arr_midi,  'ro') # it look better with the points but we can delete this parameter\n",
    "    plt.xlabel(\"frame\")\n",
    "    plt.ylabel(\"MIDI\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yaI3MfILRjXu"
   },
   "source": [
    "#### Pitch detection for oboe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 651
    },
    "colab_type": "code",
    "id": "_ZwIYVVWRjXw",
    "outputId": "fd07a191-1273-428c-a1cd-fdaca1ed726c"
   },
   "outputs": [],
   "source": [
    "pitch_detection_in_frames(x) #@todo discuss frame + hop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "18bxp_DxRjX6"
   },
   "source": [
    "#### Pitch detection for organ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 651
    },
    "colab_type": "code",
    "id": "IuW_O4AeRjX7",
    "outputId": "7ad49380-0f59-4c0f-fbd7-f6a5998a041a"
   },
   "outputs": [],
   "source": [
    "pitch_detection_in_frames(x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WXj9icE4RjYB"
   },
   "source": [
    "#### Is any of these representations ( 1) or 2) ) a chromagram? Explain your answer.\n",
    "maybe we will find out by changing the frame size ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2rg-sh5BRjYC"
   },
   "source": [
    "## Task 2 – Rhythm\n",
    "As you've seen, the ACF may be used to estimate the periodicity of a signal. Last week, I asked you to think about other main characteristics of the music signals may be characterised by periodicities, and if it would make sense to use the autocorrelation function for those potential tasks. I assume you already know the answer: yes!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "colab_type": "code",
    "id": "1slmKrBPRjYF",
    "outputId": "a2639b6d-5477-4bf2-a79f-f4ec24f50fff"
   },
   "outputs": [],
   "source": [
    "x3, sr3 = librosa.load(path+audio_files+'rhythm.wav')\n",
    "ipd.Audio(x3, rate=sr3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eGg4-RCsRjYS"
   },
   "outputs": [],
   "source": [
    "def beats(x, sr):\n",
    "    # Track beats using a pre-computed onset envelope\n",
    "    onset_env = librosa.onset.onset_strength(x, sr=sr, aggregate=numpy.median)\n",
    "    '''\n",
    "            1. Measure onset strength\n",
    "            2. Estimate tempo from onset correlation\n",
    "            3. Pick peaks in onset strength approximately consistent with estimated tempo\n",
    "    '''\n",
    "    tempo, beats = librosa.beat.beat_track(onset_envelope=onset_env,sr=sr)\n",
    "    hop_length = 512\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    times = librosa.times_like(onset_env, sr=sr, hop_length=hop_length)\n",
    "    plt.plot(times, librosa.util.normalize(onset_env),label='Onset strength')\n",
    "    plt.vlines(times[beats], 0, 1, alpha=0.5, color='r', linestyle='--', label='Beats')\n",
    "    #print(times[beats])\n",
    "    plt.legend(frameon=True, framealpha=0.75)\n",
    "    # Limit the plot to a 15-second window\n",
    "    plt.xlim(0, 9)\n",
    "    plt.gca().xaxis.set_major_formatter(librosa.display.TimeFormatter())\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # clicks at beat times\n",
    "    times = librosa.frames_to_time(beats, sr=sr)\n",
    "    y_beat_times = librosa.clicks(times=times, sr=sr,length=len(x))\n",
    "    #clicks = librosa.clicks(frames=beats, sr=sr, length=len(x))\n",
    "    return y_beat_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 409
    },
    "colab_type": "code",
    "id": "VLEI7nQbRjYh",
    "outputId": "7ddf5f6a-b9fe-4ea5-846d-a0bbecae32b8",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clicks = beats(x3, sr3)\n",
    "#print(clicks)\n",
    "ipd.Audio(x3 + clicks, rate=sr3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7uPPpz8tRjYw"
   },
   "source": [
    "#### Do a subjective evaluation on the quality of the beat tracking.\n",
    "I think the quality is very good. I don't hear any deviation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LYofuRFdRjYx"
   },
   "source": [
    "#### This rhythm shows a steady constant tempo. Obtain the global tempo estimative in bpm (you can do it by hand, no need to code it).\n",
    "My estimation:\n",
    "BMP = Beats per minute \n",
    "13 clicks in 6.7 sec => 117 BMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "NDhQCb30RjYy",
    "outputId": "1cf2287a-2cae-4184-c419-514692960d17"
   },
   "outputs": [],
   "source": [
    "60/6.65*13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "mCPyuK3BRjZB",
    "outputId": "783e16d3-c357-4d18-b9cd-30ade7bbed99"
   },
   "outputs": [],
   "source": [
    "# just to verify\n",
    "onset_env = librosa.onset.onset_strength(x3, sr=sr3)\n",
    "librosa.beat.tempo(onset_envelope=onset_env, sr=sr3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ijn8t2tPRjZL"
   },
   "source": [
    "#### How many downbeats are in this musical example? At what times?\n",
    "downbeat = the first beat of each bar\n",
    "\n",
    "I really don't see these graphs so helpful because the loudness here does not correspond to the downbeat as this rhythm does not follow this rule. From my point of view:\n",
    "\n",
    "There are 2 downbeats (in 0 and 4,2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "colab_type": "code",
    "id": "BnRjM5a3RjZP",
    "outputId": "2b75845b-2aeb-40fb-e8b1-1b259232791d"
   },
   "outputs": [],
   "source": [
    "# https://github.com/librosa/librosa/issues/1065\n",
    "# detecting downbeats according to louness\n",
    "import librosa\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import scipy.signal\n",
    "\n",
    "threshold = 0.1\n",
    "hop_length = 512\n",
    "input_path = path+audio_files+'rhythm.wav'\n",
    "\n",
    "y, sr = librosa.load(input_path, sr=None)\n",
    "rms = librosa.feature.rms(y, hop_length=hop_length)[0, :]\n",
    "peak_locs = scipy.signal.find_peaks(rms, height=threshold)[0]\n",
    "peak_heights = rms[peak_locs]\n",
    "\n",
    "times = librosa.times_like(rms, hop_length=hop_length, sr=sr)\n",
    "plt.plot(times, rms, label=\"Energy (RMS)\");\n",
    "plt.plot(times, threshold*np.ones_like(rms), '--', label=\"Threshold\")\n",
    "plt.plot(times[peak_locs], peak_heights, 'o', label=\"Detected peaks\")\n",
    "\n",
    "plt.xlim(0, np.ceil(librosa.get_duration(y, sr)))\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylim(0, 2*threshold)\n",
    "plt.title(\"Downbeat tracking of {}\".format(os.path.split(input_path)[1]))\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "colab_type": "code",
    "id": "-00XKA7qRjZb",
    "outputId": "49d73b91-e47a-4007-bc24-0feac35a36be"
   },
   "outputs": [],
   "source": [
    "# What would you obtain if you applied the autocorrelation function to this novelty function\n",
    "rm_auto = librosa.autocorrelate(rms, max_size=5000)\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.plot(rm_auto[:2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "VfvfHnCTRjZr",
    "outputId": "cbbdac5d-711d-4040-8297-80da2fef26a4"
   },
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/57384448/detecting-beat-energy-with-librosa-finding-the-first-beat-of-each-bar\n",
    "import numpy as np\n",
    "\n",
    "y, sr = librosa.load(path+audio_files+'rhythm.wav')\n",
    "# get onset envelope\n",
    "onset_env = librosa.onset.onset_strength(y, sr=sr, aggregate=np.median)\n",
    "# get tempo and beats\n",
    "tempo, beats = librosa.beat.beat_track(onset_envelope=onset_env, sr=sr)\n",
    "# we assume 4/4 time\n",
    "meter = 4\n",
    "# calculate number of full measures \n",
    "measures = (len(beats) // meter)\n",
    "# get onset strengths for the known beat positions\n",
    "# Note: this is somewhat naive, as the main strength may be *around*\n",
    "#       rather than *on* the detected beat position. \n",
    "beat_strengths = onset_env[beats]\n",
    "# make sure we only consider full measures\n",
    "# and convert to 2d array with indices for measure and beatpos\n",
    "measure_beat_strengths = beat_strengths[:measures * meter].reshape(-1, meter)\n",
    "# add up strengths per beat position\n",
    "beat_pos_strength = np.sum(measure_beat_strengths, axis=0)\n",
    "# find the beat position with max strength\n",
    "downbeat_pos = np.argmax(beat_pos_strength)\n",
    "# convert the beat positions to the same 2d measure format\n",
    "full_measure_beats = beats[:measures * meter].reshape(-1, meter)\n",
    "# and select the beat position we want: downbeat_pos\n",
    "downbeat_frames = full_measure_beats[:, downbeat_pos]\n",
    "print('Downbeat frames: {}'.format(downbeat_frames))\n",
    "# print times\n",
    "downbeat_times = librosa.frames_to_time(downbeat_frames, sr=sr)\n",
    "print('Downbeat times in s: {}'.format(downbeat_times))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "colab_type": "code",
    "id": "YIRt8aLuRjZ6",
    "outputId": "97a25b6b-f9f7-4f75-a0eb-9e9fa5cec4bc"
   },
   "outputs": [],
   "source": [
    "# What would you obtain if you applied the autocorrelation function to this novelty function\n",
    "beat_auto = librosa.autocorrelate(beat_strengths, max_size=5000)\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.plot(beat_auto[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-_pDQh3hRjaC"
   },
   "source": [
    "#### What is the novelty function that you used? (i.e., the library implements). What functions do you know that could be used for the same end?\n",
    "- librosa.feature.rms, librosa.beat.beat_track\n",
    "Some functions that counts loudness, energy etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5CkWd-_9RjaD"
   },
   "source": [
    "#### What would you obtain if you applied the autocorrelation function to this novelty function? Explain your answer.\n",
    "Decreasing shape. Don't know why so far."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HthAC04YRjaE"
   },
   "source": [
    "## Task 3 – Pitch and Rhythm I\n",
    "Download voice.wav. This music excerpt contains 9 notes (part of a musical scale), singed by a feminine voice. With the help of Sonic Visualiser, answer the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WJ0z8YBPRjaF"
   },
   "source": [
    "#### What is the chroma and height of the 9 notes?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t8NjJGnnRjaG"
   },
   "source": [
    "As we can see from the chromagram: [Chromagram of voice](https://drive.google.com/file/d/1a16-KdOSk4O3ZXhKxLLo-8QMW19Oe125/view?usp=sharing)\n",
    "it is too complicated to understand clearly what are the notes.\n",
    "\n",
    "Based on our intuition we suppose each note is represented by the **most dominant color** in the chromagram.\n",
    "\n",
    "These are:\n",
    "1. A or A#\n",
    "2. C\n",
    "3. G\n",
    "4. A or A#\n",
    "5. E\n",
    "6. (A or A#) or (D or D#)\n",
    "7. G#\n",
    "8. C\n",
    "9. E"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C7wgUbFIRjaH"
   },
   "source": [
    "#### Assuming each note represents a beat, what is the tempo (in bpm) of this excerpt.\n",
    "It has 8 seconds and there are 9 notes => 67,5 BPM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "nWP9SlEBRjaI",
    "outputId": "78806e2c-0f48-4894-8d27-e2c8d650ff10"
   },
   "outputs": [],
   "source": [
    "60/8*9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gM2ZcXlTRjaX"
   },
   "source": [
    "## Task 4 – Pitch and Rhythm II\n",
    "Hint: You already have most of the code needed for this to work. For a quick fix to obtain the expected result you’ll need to add the following:\n",
    "- Choose the frames in which you have to estimate the pitch (exclude the silences).\n",
    "- Choose a way to average the estimates for each note across the different frames.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "colab_type": "code",
    "id": "dweWGydXC6kB",
    "outputId": "dc1bcec9-e3c9-44ea-b19f-3a7756c855d4"
   },
   "outputs": [],
   "source": [
    "x4, sr4 = librosa.load(path+audio_files+'voice.wav')\n",
    "ipd.Audio(x4, rate=sr4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "colab_type": "code",
    "id": "VUdmug_R0gRw",
    "outputId": "fc56ece8-c7e0-4c52-c664-f7f37e19c896"
   },
   "outputs": [],
   "source": [
    "rms = librosa.feature.rms(x4, hop_length=hop_length)[0, :]\n",
    "\n",
    "plt.plot(rms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "2HjxghH6QTl5",
    "outputId": "01658a6f-1782-48f6-8475-8cdbde7960b2"
   },
   "outputs": [],
   "source": [
    "pip install --upgrade pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4A6VtFpRQCuJ"
   },
   "outputs": [],
   "source": [
    "# Split the audio signal into non-silent intervals\n",
    "def split(sound, threshold=50):\n",
    "    non_silence = librosa.effects.split(sound, threshold)\n",
    "    list_of_notes = list()\n",
    "    for k in non_silence:\n",
    "        # print(k[0], k[1])\n",
    "        start = k[0]\n",
    "        end = k[1]+1\n",
    "        temp_list = list()\n",
    "        for i in range(start, end):\n",
    "            temp_list.append(sound[i])\n",
    "        temp_array = np.array(temp_list)\n",
    "        list_of_notes.append(temp_array)\n",
    "    return list_of_notes\n",
    "\n",
    "notes = split(x4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "-bS9hkREUfur",
    "outputId": "4f9c111a-0947-4681-e35f-baade3a70c4a"
   },
   "outputs": [],
   "source": [
    "chroma_list = list()\n",
    "for i in notes:\n",
    "    chroma_list.append(librosa.feature.chroma_stft(y=i, sr=sr4))\n",
    "\n",
    "for chroma in chroma_list:\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    librosa.display.specshow(chroma, y_axis='chroma', x_axis='time')\n",
    "    plt.colorbar()\n",
    "    plt.title('Chromagram')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DuHxGZRRQ4bn"
   },
   "source": [
    "We can see that the file is splited in 9 sections, exactly like the notes sang by the feminene voice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "colab_type": "code",
    "id": "dZ5mEDHdKw_T",
    "outputId": "8fe1325a-010b-4e33-bc38-d194303a02e9"
   },
   "outputs": [],
   "source": [
    "# What would you obtain if you applied the autocorrelation function to this novelty function\n",
    "rm_auto = librosa.autocorrelate(rms, max_size=5000)\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "plt.plot(rm_auto[:2000])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "WXj9icE4RjYB",
    "7uPPpz8tRjYw",
    "-_pDQh3hRjaC",
    "5CkWd-_9RjaD"
   ],
   "name": "Assignment3_G10.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
